---
title: "Swimming downstream: statistical analysis of differential transcript usage following Salmon quantification"
author:
- name: Michael I. Love
  affiliation: 
  - Department of Biostatistics, UNC-Chapel Hill, Chapel Hill, NC, US
  - Department of Genetics, UNC-Chapel Hill, Chapel Hill, NC, US
- name: Rob Patro
  affiliation: Department of Computer Science, Stony Brook University
date: 5 June, 2018
vignette: >
  %\VignetteIndexEntry{RNA-seq workflow for differential transcript usage following Salmon quantification}
  %\VignetteEngine{knitr::rmarkdown}
abstract: |
  RNA-seq workflow for differential transcript usage following Salmon quantification.
keywords: RNA-seq, workflow, differential transcript usage, Salmon, DRIMSeq, DEXSeq, stageR, tximport
bibliography: bibliography.bib
output: BiocWorkflowTools::f1000_article
---

<!-- to compile this: 
  rmarkdown::render("rnaseqDTU.Rmd")
-->

<!-- a list of all required libraries:
  reqlibs = sub(".*library\\((.*?)\\).*","\\1",grep("library\\(",readLines("rnaseqDTU.Rmd"),value=TRUE))
  find.package(reqlibs)
-->

```{r style, echo=FALSE, message=FALSE, warning=FALSE, results="asis"}
library(knitr)
library(rmarkdown)
opts_chunk$set(message=TRUE, warning=FALSE, error=FALSE, 
               cache=TRUE, fig.width=5, fig.height=5)
```

**R version**: `r R.version.string`

**Bioconductor version**: `r BiocInstaller::biocVersion()`

<!-- fix this to rnaseqDTU later -->
**Package**: `r packageVersion("DRIMSeq")`

# Introduction

RNA-seq experiments can be analyzed to detect changes across groups of
samples in total gene expression, i.e. the total number of transcripts
produced by all isoforms of a gene, and additionally differences in
transcript usage within a gene. If the number of expressed transcripts
switches among two or more isoforms of a gene, then the total gene
expression may not change by a detectable amount, but such
differential transcript usage is of interest to biological and
biomedical researchers. While many packages and workflows in the
Bioconductor project address differential gene expression, there are
fewer guides for performing a differential transcript usage analysis,
which provides critical and complementary information to a the
gene-level analysis. Some of the existing packages and vignettes that 
can be used to detect differential transcript usage include *BitSeq*, 
*DEXSeq* (originally designed for differential exon usage), `diffSpliceDGE` 
from the *edgeR* package, `diffSplice` from the *limma* package, *DRIMSeq*, 
*stageR*, and *IsoformSwitchAnalyzeR*. 
Others can be found at the following link: 
<https://bioconductor.org/packages/release/BiocViews.html#___DifferentialSplicing>

Previously, some of the developers of the Bioconductor packages
*edgeR* and *DESeq2* (cite) have collaborated to develop the
*tximport* package (cite) for summarizing the output of fast
transcript-level quantifiers, such as *Salmon* [@Patro2017Salmon],
*Sailfish*, and *kallisto* (cite). The *tximport* package focuses on
preparing estimated transcript-level quantities, counts, abundances
and effective transcript lengths, for gene-level statistical analysis
using *edgeR*, *DESeq* or *limma-voom* (cite). *tximport* produces an
offset matrix to accompany gene-level counts, that accounts for
various RNA-seq biases (cite Salmon) as well as differences in
transcript usage among transcripts of different length that would bias
an estimator of fold change based on the gene-level counts (cite
Trapnell). *tximport* can alternatively produce a matrix of data that
is roughly on the scale of counts, by scaling abundances to add up to
the total number of reads, which directly corrects for technical
biases and differential transcript usage across samples, obviating the
need for the accompanying offset matrix.

Complementary to an analysis of differential gene expression, one can
use *tximport* to import transcript-level counts, and then pass these
counts to packages such as *DRIMSeq* or *DEXSeq* for statistical
analysis of differential transcript usage. Following a
transcript-level analysis, one can aggregate evidence of differential
transcript usage to the gene-level. The *stageR* package in
Bioconductor provides a statistcal framework for screening for
differential transcript usage using gene-level adjusted p-values,
followed by confirmation of which transcripts are differential using
transcript-level adjusted p-values (cite). The method provides
_overall false discovery rate_ error control for such a two-stage
procedure, which will be discussed in more detail later in the
workflow. We believe that this represents a principled approach to
analyzing transcript usage changes, as the  methods can be evaluated
against a target error rate in a manner that mimics how the methods
would actually be used in practice. That is, following rejection of
the null hypothesis at the gene-level, investigators would likely
desire to know which transcripts within a gene participated in the
differential usage. 

Here we provide a simple workflow for detecting
differential transcript abundance using Bioconductor packages,
following quantification of transcript abundance using the *Salmon*
method. This workflow includes live, runnable code chunks for analysis
using the *DRIMSeq* and *DEXSeq*, as well as for performing stage-wise
testing of differential transcript usage using the *stageR*
package. For the workflow, we use data which is simulated with
experimental parameters estimated from the GEUVADIS dataset, so that
we can also evaluate the performance of methods for differential
transcript usage, as well as differential gene and transcript
expression.

# Methods

## Simulation

First we describe details of the simulated data, which will be used in
the following workflow. Understanding the details of the
simulation will be useful for assessing the methods in the later sections.
All of the code used to simulate RNA-seq experiments and write
paired-end reads can be found at the following
link: <https://github.com/mikelove/swimdownsim>. *alpine* was used to
estimate realistic fragment GC bias from 12 samples from the GEUVADIS
project from the same center (cite alpine and GEUVADIS). *DESeq2* was
used to estimate mean and dispersion parameters for a Negative
Binomial distribution for gene-level counts for 462 GEUVADIS samples
provided by the *recount2* project (cite DESeq2, recounts2).
*polyester* was used to simulate paired-end RNA-seq reads for two
groups of 12 samples each, with realistic fragment GC bias, and with
dispersion on transcript-level counts following the joint distribution
of mean and dispersion values estimated from the GEUVADIS samples. The
first sample for group 1 and the first sample for group 2 followed the
realistic GC bias profile of the same sample, and so on for all 12
samples. This pairing of the samples was used to generate balanced
data, but not used in the statistical analysis. The baseline for
transcript abundances was taken from Salmon estimates for a single
sample of the GEUVADIS project (cite Salmon). *countsimQC* was used to
examine the properties of the simulation relative to the dataset used
for parameter estimation, and the full report can be accessed at the
following link: <https://github.com/mikelove/swimdownsim/countsimqc>
(cite countsimqc).

Differential expression across two groups was generated as follows:
70% of the genes were set as "null genes", where abundance was not
changed across two groups. For 10% of genes, all isoforms were
differentially expressed at a log fold change between 1 and 2.58. This
set of genes and transcripts were classified as "DGE", differential
gene expression, but did not count as "DTU", differential transcript
usage. To simulate balanced differential expression, randomly one of
the two groups was chosen to be the baseline, and the other group
would have its counts multiplied by the fold change. For 10% of genes,
a single expressed isoform was differentially expressed at a log fold
change between 1 and 2.58. This set of genes was termed "DTE",
differential transcript expression. If the chosen transcript was the
only expressed isoform of a gene, this counted as DGE and not DTU,
but if there were other isoforms which are expressed, such genes
counted for both DGE and DTU, as the proportion of expression among
the isoforms was affected. For 10% of genes, differential transcript
usage was constructed by exchanging the abundance of two expressed
isoforms, or if only one isoform was expressed, exchanging the
abundance of the expressed isoform with a non-expressed one. Such
genes counted for DTU, but not for DGE.

```{r ma-simulated, messages=FALSE, echo=FALSE, dev="png", out.width="50%", fig.cap="MA plot of simulated abundances. Each point depicts a transcript, with the average of log2 abundance (TPM) on the x-axis and the difference between the two groups on the y-axis. Of the transcripts which were expressed with TPM > 1 in at least one group, 77\\% are null transcripts (grey), and 23\\% are differentially expressed (green, orange, or purple)."}
load("simulate.rda")
library(rafalib)
bigpar()
pc <- 1
col <- rep(8, nrow(tpms))
col[iso.dge] <- 1
col[iso.dte] <- 2
col[iso.dtu] <- 3
maplot(log2(tpms[,1]+pc), log2(tpms[,2]+pc),
       n=nrow(tpms), curve.add=FALSE,
       col=col, cex=.25, pch=20)
legend("bottomright",
       c("DGE","DTE","DTU","null"),
       col=c(1:3,8), pch=20, bty="n")
```

## Operation

This workflow was designed to work with R 3.5 or higher, and the
*DRIMSeq*, *DEXSeq*, *stageR* and *tximport* packages for Bioconductor
version 3.7 or higher. Bioconductor packages should always be
installed following the [official instructions](https://bioconductor.org/install).
The workflow uses a subset of all genes to speed
up the analysis, but the Bioconductor packages can easily be run for
this dataset on all human genes on a laptop in less than an
hour. Timing for the various packages is included within each section.

# Salmon quantification

We used *Salmon* version 0.10.0 to quantify abundance and effective
lengths for all of the 24 simulated samples. For this workflow, we
will use the first six samples from each group. We quantified against
the [GENCODE](https://www.gencodegenes.org/releases/current.html)
human annotation version 28, which was the same reference used to
generate the simulated reads. We used the transcript sequences FASTA
file which contains "Nucleotide sequences of all transcripts on the
reference chromosomes". When downloading the FASTA file, it is useful
to download the corresponding GTF file, as this will be used in later
sections. 

To build the *Salmon* index, we used the following command:

```
salmon index -t gencode.v28.transcripts.fa -i gencode.v28_salmon-0.10.0
```

To quantify each sample, we used the following command, which uses 6
threads, and performs fragment GC bias modeling. The library type is
specified by `-l IU` and is discussed at this link:
<http://salmon.readthedocs.io/en/latest/library_type.html>. The latest
versions of Salmon can automatically detect the library type by
setting `-l A`. Such a command can be automated in a bash loop using
bash variables, or one can use more advanced workflow management
systems such as Snakemake or Nextflow (cite).

```
salmon quant -p 6 -i gencode.v28_salmon-0.10.0 -l IU \
      --gcBias -o sample -1 sample_1.fa.gz -2 sample_2.fa.gz
```

# Importing counts into R/Bioconductor

We can use *tximport* to import the estimated counts, abundances and
effective transcript lengths into R. We recommend to keep a CSV file
that keeps track of the sample identifiers and any relevant variables,
e.g. condition, time point, batch, and so on. Here we have made a
sample CSV file which records which sample is condition 1 and which is
condition 2. The columns of this CSV can have any names, although
`sample_id` will be used later by *DRIMSeq*, and so using this column
name allows us to pass this *data.frame* directly to *DRIMSeq* at a
later step.

```{r}
samps <- read.csv("samples.csv")
head(samps)
samps$condition <- factor(samps$condition)
table(samps$condition)
files <- file.path("/path/to/dir", samps$sample_id, "quant.sf")
names(files) <- samps$sample_id
head(files)
```

We can then import transcript-level counts using the following
call. Here we suggest to generate counts from abundance, using the
`scaledTPM` method described by Soneson et al (cite). As described
above, the `countsFromAbundance` option of *tximport* uses estimated
abundances to generate roughly count-scaled data, such that each
column will sum to the number of reads generated for that library. One
reason we suggest to use `scaledTPM` for differential transcript usage
is that the estimated proportions that will be fit by *DRIMSeq* in
following sections will correspond to proportions of abundance. 

The following code chunk is not evaluated, but instead we will load a
pre-constructed matrix of counts.

```{r eval=FALSE}
library(tximport)
txi <- tximport(files, type="salmon", txOut=TRUE,
                countsFromAbundance="scaledTPM")
cts <- txi$counts
cts <- cts[rowSums(cts) > 0,]
```

If we used the estimated counts themselves,
or `lengthScaledTPM`, then a change in transcript usage between
transcripts of different length could result in a changed total count
for the gene, even if there is no change in total gene
expression. While this could be corrected by an offset, this is not
easily implemented in the current packages. While this workflow only
considers existing software features, we are considering developing a new
`countsFromAbundance` method which would scale abundance for all
transcripts of a gene by a fixed gene length, then each sample by its
number of reads, therefore balancing between the benefits of
`scaledTPM` and `lengthScaledTPM`.

# Transcript-to-gene mapping

Bioconductor offers numerous approaches for building a *TxDb* object,
a transcript database that can be used to link transcripts to genes.
We used the following unevaluated code chunks to generate a *TxDb*, and
then we will use the *data.frame* called `txdf` in following
sections. The version 28 human GTF file was downloaded from the
GENCODE website when we downloaded the transcripts FASTA file.

```{r eval=FALSE}
library(GenomicFeatures)
gtf <- "gencode.v28.annotation.gtf.gz"
txdb.filename <- "gencode.v28.annotation.sqlite"
txdb <- makeTxDbFromGFF(gtf)
saveDb(txdb, txdb.filename)
```

Once the *TxDb* database has been saved, it can be quickly reloaded:

```{r eval=FALSE}
txdb <- loadDb(txdb.filename)
txdf <- select(txdb, keys(txdb, "GENEID"), "TXNAME", "GENEID")
tab <- table(txdf$GENEID)
txdf$ntx <- tab[match(txdf$GENEID, names(tab))]
```

# DRIMSeq

We load the `cts` object as created in the code chunk above. This
contains count-scale data, generated from abundance using the
`scaledTPM` method. The column sums are equal to the number of
paired-end reads per experiment. The experiments have between 31 and
38 million paired-end reads that were mapped to the transcriptome
using *Salmon*.

```{r}
load("salmon_cts.rda")
cts[1:3,1:3]
range(colSums(cts)/1e6)
```

We also have the `txdf` object giving the transcript-to-gene
mappings. This is contained in a file called `simulate.rda` that
contains a number of R objects with information about the
simulation, that we will use later to assess the methods'
performance. 

```{r}
load("simulate.rda")
head(txdf)
all(rownames(cts) %in% txdf$TXNAME)
txdf <- txdf[match(rownames(cts),txdf$TXNAME),]
all(rownames(cts) == txdf$TXNAME)
```

In order to run *DRIMSeq* we build a *data.frame* with the gene ID,
the feature ID, and then columns for each of the samples:

```{r}
counts <- data.frame(gene_id=txdf$GENEID,
                     feature_id=txdf$TXNAME,
                     cts)
```

We can now load the DRIMSeq package and create a *dmDSdata* object,
with our `counts` and `samps` *data.frames*. Typing in the object name
and pressing return will give information about the number of genes:

```{r}
library(DRIMSeq)
d <- dmDSdata(counts=counts, samples=samps)
d
```

The *dmDSdata* object has a number of specific methods. Note that the
rows of the object are gene-oriented, so pulling out the first *row*
corresponds to all of the transcripts of the first gene:

```{r}
methods(class=class(d))
counts(d[1,])[,1:4]
```

It will be useful to first filter the object, before running
procedures to estimate model parameters. It greatly speeds up the
fitting and removes transcripts which would be troublesome for
parameter estimation, e.g. estimating the proportion of expression
among the transcripts of a gene when the total count is very low. We first
define `n` to be the total number of samples, and `n.small` to be the
sample size of the smallest group. We use all
three of the possible filters: we require that (1) at least `n.small`
samples have a count of 10, for a transcript to be included in the
dataset, (2) at least `n.small` samples have a proportion of 0.1 or
larger, and (3) that all `n` samples have a total count of 10 or
more. If `n` was large, it would make sense to allow perhaps a few
samples to have very low counts, so lowering `min_samps_gene_expr` to
some multiple of `n`, likewise for the first two filters. After
filtering, the dataset has only 7,764 genes.

```{r}
n <- 12
n.small <- 6
d <- dmFilter(d,
              min_samps_feature_expr=n.small, min_feature_expr=10,
              min_samps_feature_prop=n.small, min_feature_prop=0.1,
              min_samps_gene_expr=n, min_gene_expr=10)
d
```

The following plot gives a useful overview:

```{r data-hist, out.width="50%", fig.cap="Histogram of the number of genes by number of transcipts."}
plotData(d)
```

We create a design matrix, using a design formula and the sample
information contained in the object, accessed via *samples*. Here we
use a simple design with just two groups, but more complex designs are
possible. For some discussion of complex designs, one can reference
the vignettes of the *limma*, *edgeR*, or *DESeq2* packages.

```{r}
design_full <- model.matrix(~condition, data=DRIMSeq::samples(d))
colnames(design_full)
```

Only for speeding up the code evaluations in this workflow, we subset
to the first 250 genes, representing about one thirtieth of the
dataset. This step would not be run in a typical workflow.

```{r}
d <- d[1:250,]
7750 / 250
```

We then use the following three functions to estimate the model
parameters. We first estimate the *precision*, which is related to the
dispersion in the Negative Binomial via the formula below. Because
precision is in the denominator of the right hand side of the
equation, they are inversely related. Higher *dispersion* -- counts more
variable around their expected value -- is associated with lower
*precision*. For full details about the DRIMSeq model, one should read
both the DRIMSeq software vignette and the DRIMSeq publication
(cite). After estimating the precision, we fit regression coefficients
and perform null hypothesis testing on the coefficient of
interest. Because we have a simple two-group model, we test the
coefficient associated with the difference between condition 2 and
condition 1, called `condition2`. The following code takes about half
a minute, and so a full analysis on this dataset takes about 15
minutes on a laptop.

\[ \textrm{dispersion} = \frac{1}{1 + \textrm{precision}} \]

```{r}
set.seed(1)
system.time({
  d <- dmPrecision(d, design=design_full)
  d <- dmFit(d, design=design_full)
  d <- dmTest(d, coef="condition2")
})
```

To build a results table, we run the `results` function. We can
generate a single p-value per gene, which tests whether there is any
differential transcript usage, or a single p-value per transcript,
which tests whether the proportions for this transcript changed within
the gene:

```{r}
res <- DRIMSeq::results(d)
head(res)
res.txp <- DRIMSeq::results(d, level="feature")
head(res.txp)
```

Because the `pvalue` column may contain `NA` values, we use the
following function to turn these into 1's. The `NA` values would
otherwise cause problems for the stage-wise analysis.

```{r}
no.na <- function(x) ifelse(is.na(x), 1, x)
res$pvalue <- no.na(res$pvalue)
res.txp$pvalue <- no.na(res.txp$pvalue)
```

We can plot the estimated proportions for one of the significant
genes, where we can see evidence of switching.

```{r plot-prop, out.width="50%", fig.cap="Estimated proportions for one of the significant genes."}
idx <- which(res$adj_pvalue < 0.05)[1]
res[idx,]
plotProportions(d, res$gene_id[idx], "condition")
```

# stageR following DRIMSeq

Because we have been working with only a subset of the data, we now
load the results tables that would have been generated by running
*DRIMSeq* functions on the entire dataset.

```{r}
load("drim_tables.rda")
nrow(res)
nrow(res.txp)
```

A typical analysis of differential transcript usage would involve
asking first: "which genes contain any evidence of DTU?", and secondly
"which transcripts in the genes that contain some evidence may be
participating in the DTU?". Note that a gene may pass the first
stage, although there is not enough evidence to identify one or more
transcripts that are participating. The *stageR* package is designed
to allow for such two-stage testing procedures, where the first stage
is called a *screening* stage and the second stage a *confirmation*
stage (cite). The methods are general, and can also be applied to
testing, for example changes across a time series followed by
investigation of individual timepoints, as shown in the *stageR*
package vignette. We show below how *stageR* is used to detect DTU and
how to interpret its output.

We first construct a vector of p-values for the screening
stage. Because of how the *stageR* package will combine transcript and
gene names, we need to strip the gene and transcript version numbers
from their Ensembl IDs (so taking the first 15 characters).

```{r}
pScreen <- res$pvalue
strp <- function(x) substr(x,1,15)
names(pScreen) <- strp(res$gene_id)
```

We construct a one column matrix of the confirmation p-values:

```{r}
pConfirmation <- matrix(res.txp$pvalue, ncol=1)
rownames(pConfirmation) <- strp(res.txp$feature_id)
```

We arrange a two column *data.frame* with the transcript and gene
identifiers.

```{r}
tx2gene <- res.txp[, c("feature_id", "gene_id")]
for (i in 1:2) tx2gene[,i] <- strp(tx2gene[,i])
```

The following functions then perform the analysis. We must specify an
`alpha` which will the *overall false discovery rate* target for the
analysis, which will be defined below. Unlike typical adjusted p-values or
q-values, we cannot choose an arbitrary threshold later: after
specifying `alpha=0.05`, we need to use 5% as the target in downstream
steps. There are also convenience functions *getSignificantGenes* and
*getSignificantTx* which are shown in the *stageR* vignette.

```{r message=FALSE}
library(stageR)
stageRObj <- stageRTx(pScreen=pScreen, pConfirmation=pConfirmation,
                      pScreenAdjusted=FALSE, tx2gene=tx2gene)
stageRObj <- stageWiseAdjustment(object=stageRObj, method="dtu", alpha=0.05)
suppressWarnings({
  drim.padj <- getAdjustedPValues(stageRObj, order=FALSE,
                                  onlySignificantGenes=TRUE)
})
head(drim.padj)
```

The final table with adjusted p-values summarizes the information from
the two stage analysis. Only genes which passed the filter are
included in the table, so the table already represents *screened* genes. 
The transcripts with `transcript` less than 0.05 pass the
*confirmation* stage and have a target 5% *overall false
discovery rate*, or OFDR. This means that, in expectation, no more
than 5% of the genes that pass screening will either (1) not contain
any DTU, so be falsely screened genes, or (2) contain a transcript with a
transcript adjusted p-value less than 0.05 which does not participate
in DTU, so contain a falsely confirmed transcript. The *stageR*
procedure allows us to look at both the genes that passed the
screening stage and the transcripts with adjusted p-values less than 
our target `alpha`, and understand what kind of *overall* error rate
this procedure entails. This cannot be said for an arbitrary procedure
of looking at simple gene adjusted p-values and transcript adjusted
p-values, where the adjustment was performed independently.

# Filtering on the change in proportions

We found that *DRIMSeq* was sensitive to detect DTU, but could exceed
its FDR bounds if we considered either the gene-level tests or the
transcript-level tests. We found that a post-hoc filtering of the
*DRIMSeq* results table to exclude transcripts with small estimated
change in proportions brought the observed FDR closer to its nominal
target, and so we provide example code for this filtering here:

TODO fix `getDpsi`

```{r}
# this needs to be re-written to be safe to its assumptions
getDpsi <- function(d, n.sub) {
  prop.d <- proportions(d)
  fitted <- subset(prop.d, select=-c(gene_id, feature_id))[,c(1,n.sub+1)]
  abs(fitted[,2] - fitted[,1])
}
res.txp.filt <- DRIMSeq::results(d, level="feature")
res.txp.filt$dpsi <- getDpsi(d, 6)
res.txp.filt$pvalue[res.txp.filt$dpsi < .1] <- 1
res.txp.filt$adj_pvalue[res.txp.filt$dpsi < .1] <- 1
```

# DEXSeq

The *DEXSeq* package was originally designed for detecting
differential exon usage (cite), but can also be adapted to run on estimated
transcript counts from Salmon, in order to detect DTU. This
usage of *DEXSeq* was evaluated by (cite Soneson isoform filtering) in a
publication discussing the benefits in terms of FDR control of
filtering lowly expressed transcripts for a transcript-level
analysis. As the usage is quite different than its intended usage, we
also benchmarked its performance here. We begin with the *DRIMSeq*
filtered object, as these filters are intuitive and useful for paring
down the analysis. 

The two factors of working on isoform counts rather than
individual exons and using the *DRIMSeq* filtering options
dramatically increase the speed of *DEXSeq*, compared to running an
exon-level analysis. Another advantage is that we can benefit from
the sophisticated bias models of *Salmon*, which account for dips in
coverage on alternative exons that can otherwise throw off estimates
of transcript abundance. A disadvantage over the exon-level analysis
is that we must know in advance all of the possible isoforms that can
be generated from a gene locus, all of which are assumed to be
contained in the annotation files.

We first load the DEXSeq package and then build a *DEXSeqDataSet* from
the data contained in the *dmDStest* object (the class of the
*DRIMSeq* object changes as the results are added). The design formula
of the *DEXSeqDataSet* here uses the language "exon" but this should
be read as "transcript" for our analysis. *DEXSeq* will test, after
accounting for total gene expression for this gene and for the
proportion of this transcript relative to the others, whether there is
a condition-specific difference in the transcript proportion relative
to the others. The testing of "this" vs "others" in *DEXSeq* enables
it to be much faster than its original published version, which
involved fitting coefficients for each exon within a gene (here it
would have been for each transcript within a gene).

```{r message=FALSE}
library(DEXSeq)
sample.data <- DRIMSeq::samples(d)
count.data <- round(as.matrix(counts(d)[,-c(1:2)]))
dxd <- DEXSeqDataSet(countData=count.data,
                     sampleData=sample.data,
                     design=~sample + exon + condition:exon,
                     featureID=counts(d)$feature_id,
                     groupID=counts(d)$gene_id)
```

The following functions run the *DEXSeq* analysis. While we are only
working on a subset of the data, the full analysis for this dataset
took less than 3 minutes on a laptop.

```{r}
system.time({
  dxd <- estimateSizeFactors(dxd)
  dxd <- estimateDispersions(dxd, quiet=TRUE)
  dxd <- nbinomLRT(dxd, reduced=~sample + exon)
})
```

We then extract the results table, not filtering on mean counts (as we
have already conducted filtering via *DRIMSeq* functions. We compute a
per-gene adjusted p-value, using the *perGeneQValue* function, which
aggregates evidence from multiple tests within a gene to a single
p-value for the gene and then corrects for multiple testing across
genes (cite DEXSeq). Finally, we build a simple results table with the
per-gene adjusted p-values.

```{r}
dxr <- DEXSeqResults(dxd, independentFiltering=FALSE)
qval <- perGeneQValue(dxr)
dxr.g <- data.frame(gene=names(qval),qval)
```

For size consideration, we reduce to a simple *data.frame* for the
transcript-level results table:

```{r}
columns <- c("featureID","groupID","pvalue")
dxr <- as.data.frame(dxr[,columns])
```

# stageR following DEXSeq

Again, as we have been working with only a subset of the data, we now
load the results tables that would have been generated by running
*DEXSeq* functions on the entire dataset.

```{r}
load("dex_tables.rda")
```

If the *stageR* package has not already been loaded, we make sure to
load it, and run code very similar to that used above for *DRIMSeq*
two stage testing, with a target `alpha=0.05`.

```{r}
library(stageR)
strp <- function(x) substr(x,1,15)
pConfirmation <- matrix(dxr$pvalue,ncol=1)
dimnames(pConfirmation) <- list(strp(dxr$featureID),"transcript")
pScreen <- qval
names(pScreen) <- strp(names(pScreen))
tx2gene <- as.data.frame(dxr[,c("featureID", "groupID")])
for (i in 1:2) tx2gene[,i] <- strp(tx2gene[,i])
```

The following three functions provide a table with the OFDR control
described above. To repeat, the set of genes passing screening should
not have more than 5% of either genes which have no DTU or genes which
contain a transcript with an adjusted p-value less than 5% which do
not participate in DTU.

```{r}
stageRObj <- stageRTx(pScreen=pScreen, pConfirmation=pConfirmation,
                      pScreenAdjusted=TRUE, tx2gene=tx2gene)
stageRObj <- stageWiseAdjustment(object=stageRObj, method="dtu", alpha=0.05)
suppressWarnings({
  dex.padj <- getAdjustedPValues(stageRObj, order=FALSE, onlySignificantGenes=TRUE)
})
head(dex.padj)
```

# SUPPA2

The *SUPPA2* is a command-line software package written in Python
which also takes as input *Salmon* quantification, and so for
completeness we also show example commands and evaluated its
performance on the simulated data (cite). *SUPPA2* offers a number of
distinct features, including the ability to translate from *Salmon*
transcript-level quantifications to individual splicing events, which
are cataloged using a specific vocabulary described in the software
usage guide: <https://github.com/comprna/SUPPA>. *SUPPA2* additionally
offers differential analysis on the splicing events, which may be more
valuable to investigators than per-transcript, depending on the system
and research goals (similar to the primary exon-level primary use case of
*DEXSeq*). 

Here, as our DTU simulation involved switching between
expressed transcripts without assessing whether they were separated by
one or more splice events, and as the other two Bioconductor methods
for detecting DTU involve transcript-level analysis, we ran *SUPPA2*
in its differential transcript usage mode. We chose to filter on
transcripts with TPM larger than 1, and did not use gene-correction,
as we wanted to apply the aggregation and correction method
`perGeneQValue` from *DEXSeq* to obtain an FDR bounded set of genes
and transcripts as output. We did not perform the stage-wise analysis
of *SUPPA2* output, although this could be done by small modifications
to the above code for either *DRIMSeq* or *DEXSeq*.

We used the following R code to prepare two files containing
TPM estimates for each of the two groups, using the *tximport* object
defined above:

```{r eval=FALSE}
x <- txi$abundance
x[x < 0.01] <- 0 # eliminate very small TPMs
n <- 6 # sample size per group
write.table(x[,1:n], file=paste0("suppa/group1.tpm"), quote=FALSE, sep="\t")
write.table(x[,n + 1:n], file=paste0("suppa/group2.tpm"), quote=FALSE, sep="\t")
```

The *SUPPA2* example code can be found at the software homepage, but
we include here the code used on the 6 vs 6 analysis. The first line
generates a set of isoforms from the GTF file. The second and third
line generate PSI (percent spliced in) for each transcript from files
containing the TPMs for each group. The final line performs the
differential analysis.

```
python suppa.py generateEvents -f ioi -i gencode.v28.annotation.gtf -o suppa/isoforms
python suppa.py psiPerIsoform -g gencode.v28.annotation.gtf \
  -e suppa/group1.tpm -o suppa/group1
python suppa.py psiPerIsoform -g gencode.v28.annotation.gtf \
  -e suppa/group2.tpm -o suppa/group2
python suppa.py diffSplice -m empirical -th 1 -i suppa/isoforms.ioi \
  -p suppa/group1_isoform.psi suppa/group2_isoform.psi \
  -e suppa/group1.tpm suppa/group2.tpm -o suppa/diff_empirical
```

We then imported the analysis results into R, and computed
transcript-level adjusted p-values:

```{r eval=FALSE}
suppa <- read.delim("suppa/diff_empirical.dpsi")
names(suppa) <- c("txp.gene","dpsi","pval")
suppa$gene <- sub(";.*", "", suppa$txp.gene)
suppa$txp <- sub(".*;", "", suppa$txp.gene)
suppa <- suppa[!is.nan(suppa$dpsi),]
suppa$padj <- p.adjust(suppa$pval, method="BH")
```

And per-gene adjusted p-values, using *perGeneQValue* from *DEXSeq*:

```{r eval=FALSE}
library(DEXSeq)
suppa.dxr <- as(DataFrame(groupID=suppa$gene,
                          pvalue=suppa$pval,
                          padj=rep(1, nrow(suppa))), "DEXSeqResults")
qval <- perGeneQValue(suppa.dxr)
suppa.g <- data.frame(gene=names(qval), qval=qval)
```

# Evaluation of methods for DTU

We begin the evaluation by noting that the methods did not call many
of the DGE genes as DTU. The object `dge.genes` contains the names of
all the genes in which all the isoforms were differentially expressed
by an equal amount (so not DTU).

```{r}
res$dge <- res$gene_id %in% dge.genes
dxr.g$dge <- dxr.g$gene %in% dge.genes
sum(res$adj_pvalue[res$dge] < .05, na.rm=TRUE)
sum(res$adj_pvalue < .05, na.rm=TRUE) # total at 5%
sum(dxr.g$qval[dxr.g$dge] < .05)
sum(dxr.g$qval < .05) # total at 5%
```

# Differential gene expression

```{r eval=FALSE}
txi.g <- tximport(files, type="salmon", tx2gene=txdf[,2:1])
``` 

```{r}
load("salmon_gene_txi.rda")
library(DESeq2)
dds <- DESeqDataSetFromTximport(txi.g, samps, ~condition)
```

```{r message=FALSE}
dds <- DESeq(dds)
dres <- DESeq2::results(dds)
```

```{r}
length(dtu.genes)
table(rownames(dres)[which(dres$padj < .05)] %in% dtu.genes)
```

```{r}
all(dxr.g$gene %in% rownames(dres))
dres <- dres[dxr.g$gene,]
# we can only color because we simulated...
col <- rep(8, nrow(dres))
col[rownames(dres) %in% dge.genes] <- 1
col[rownames(dres) %in% dte.genes] <- 2
col[rownames(dres) %in% dtu.genes] <- 3
```

```{r tuge-plot, dev="png", out.width="50%", fig.cap="Transcript usage over gene expression plot. Each point represents a gene. Plotted are -log10 adjusted p-values for DEXSeq's test of differntial transcript usage (y-axis) and DESeq2's test of differential gene expression (x-axis). Because we simulated the data we can color the genes according to their true category."}
library(rafalib)
bigpar()
plot(-log10(dres$padj), -log10(dxr.g$qval), col=col,
     xlab="Gene expression",
     ylab="Transcript usage")
legend("topright",
       c("DGE","DTE","DTU","null"),
       col=c(1:3,8), pch=20, bty="n")
```

```{r message=FALSE}
library(edgeR)
cts.g <- txi.g$counts
normMat <- txi.g$length
normMat <- normMat / exp(rowMeans(log(normMat)))
o <- log(calcNormFactors(cts.g/normMat)) + log(colSums(cts.g/normMat))
y <- DGEList(cts.g)
y <- scaleOffset(y, t(t(log(normMat)) + o))
keep <- filterByExpr(y)
y <- y[keep,]
```

```{r}
y <- estimateDisp(y, design_full)
fit <- glmFit(y, design_full)
lrt <- glmLRT(fit)
tt <- topTags(lrt, n=nrow(y), sort="none")[[1]]
```

```{r}
table(rownames(tt)[which(tt$FDR < .05)] %in% dtu.genes)
```

```{r}
common <- intersect(res$gene_id, rownames(tt))
tt <- tt[common,]
res.sub <- res[match(common, res$gene_id),]
# we can only color because we simulated...
col <- rep(8, nrow(tt))
col[rownames(tt) %in% dge.genes] <- 1
col[rownames(tt) %in% dte.genes] <- 2
col[rownames(tt) %in% dtu.genes] <- 3
```

```{r tuge-drim-edger, dev="png", out.width="50%", fig.cap="Transcript usage over gene expression plot, as previously, but for DRIMSeq and edgeR."}
library(rafalib)
bigpar()
plot(-log10(tt$FDR), -log10(res.sub$adj_pvalue), col=col,
     xlab="Gene expression",
     ylab="Transcript usage")
legend("topright",
       c("DGE","DTE","DTU","null"),
       col=c(1:3,8), pch=20, bty="n")
```



# Evaluation of methods for DGE

# Evaluation of methods for DTE

# Discussion 
This section is only required if the paper includes novel data or analyses, and should be written in the same style as a traditional discussion section.
Please include a brief discussion of allowances made (if any) for controlling bias or unwanted sources of variability, and the limitations of any novel datasets.

# Conclusions 
This section is only required if the paper includes novel data or analyses, and should be written as a traditional conclusion.

# Data availability 
Please add details of where any datasets that are mentioned in the paper, and that have not have not previously been formally published, can be found.  If previously published datasets are mentioned, these should be cited in the references, as per usual scholarly conventions.

# Software availability
This section will be generated by the Editorial Office before publication. Authors are asked to provide some initial information to assist the Editorial Office, as detailed below.

1. URL link to where the software can be downloaded from or used by a non-coder (AUTHOR TO PROVIDE; optional)
2. URL link to the author's version control system repository containing the source code (AUTHOR TO PROVIDE; required)
3. Link to source code as at time of publication (*F1000Research* TO GENERATE)
4. Link to archived source code as at time of publication (*F1000Research* TO GENERATE)
5. Software license (AUTHOR TO PROVIDE; required)

# Author information
In order to give appropriate credit to each author of an article, the individual contributions of each author to the manuscript should be detailed in this section. We recommend using author initials and then stating briefly how they contributed.

# Competing interests
All financial, personal, or professional competing interests for any of the authors that could be construed to unduly influence the content of the article must be disclosed and will be displayed alongside the article. If there are no relevant competing interests to declare, please add the following: 'No competing interests were disclosed'.

# Grant information
Please state who funded the work discussed in this article, whether it is your employer, a grant funder etc. Please do not list funding that you have that is not relevant to this specific piece of research. For each funder, please state the funder’s name, the grant number where applicable, and the individual to whom the grant was assigned. If your work was not funded by any grants, please include the line: 'The author(s) declared that no grants were involved in supporting this work.'

# Acknowledgments
This section should acknowledge anyone who contributed to the research or the article but who does not qualify as an author based on the criteria provided earlier (e.g. someone or an organization that provided writing assistance). Please state how they contributed; authors should obtain permission to acknowledge from all those mentioned in the Acknowledgments section.

Please do not list grant funding in this section.

# References
